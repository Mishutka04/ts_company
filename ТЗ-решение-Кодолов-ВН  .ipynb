{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Комментарий:\n",
        "Предоставляю решение первого задания. При решении второго, столкнулся с проблемой реализации, так как я не смог найти open-source решения на python для разделения на различные голоса. Сложность заключается в том, что тут необходимо взаимодействовать с аудио-волнами, частотами, и если оба говорящих имеют +/- одинаковые голосовые показатели, то задача переходит в более сложную стадию и за 4 дня реализовать такое очень сложно. При анализе источников и решений, я нашел решение у СБЕРа, по разделению на голоса, но доступа к данной технологии у меня нету, так как необходима подписка.\n",
        "На данный момент у меня имеется решение для распознования речи и перевод ее в текст (V2T), решения по второй части имеется на половину (Без разделения на персоны), но я готов заняться данной задачей в вашей компании (Если необходимо будет внедрить решение с распознованием персон)"
      ],
      "metadata": {
        "id": "6NDuh_Qg4t7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Установка зависимостей\n",
        "\n",
        "> Добавить блок с цитатой\n",
        "\n"
      ],
      "metadata": {
        "id": "844HkDAODwSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_8_5XS6oYdB"
      },
      "outputs": [],
      "source": [
        "!pip install audio-separator\n",
        "!pip cache purge\n",
        "!pip install --force-reinstall torch torchvision torchaudio\n",
        "!pip install --force-reinstall onnxruntime-gpu\n",
        "!pip install -U git+https://github.com/jianfch/stable-ts.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Запись речи с микрофона. Примичание: В Google Collab нет возможности записывать речь с микрофона."
      ],
      "metadata": {
        "id": "uKjheZh3-8hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyaudio"
      ],
      "metadata": {
        "id": "NuTdbnRf9Kwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "\n",
        "chunk = 1024 # Запись кусками по 1024 сэмпла\n",
        "sample_format = pyaudio.paInt16 # 16 бит на выборку\n",
        "channels = 2\n",
        "rate = 44100 # Запись со скоростью 44100 выборок(samples) в секунду\n",
        "seconds = 3\n",
        "filename = \"audio.wav\"\n",
        "p = pyaudio.PyAudio() # Создать интерфейс для PortAudio\n",
        "\n",
        "print('Recording...')\n",
        "\n",
        "stream = p.open(format=sample_format,\n",
        "channels=channels,\n",
        "rate=rate,\n",
        "frames_per_buffer=chunk,\n",
        "input_device_index=2, # индекс устройства с которого будет идти запись звука\n",
        "input=True)\n",
        "\n",
        "frames = [] # Инициализировать массив для хранения кадров\n",
        "\n",
        "# Хранить данные в блоках в течение 3 секунд\n",
        "for i in range(0, int(rate / chunk * seconds)):\n",
        "  data = stream.read(chunk)\n",
        "  frames.append(data)\n",
        "\n",
        "# Остановить и закрыть поток\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "# Завершить интерфейс PortAudio\n",
        "p.terminate()\n",
        "\n",
        "print('Finished recording!')\n",
        "\n",
        "# Сохранить записанные данные в виде файла WAV\n",
        "wf = wave.open(filename, 'wb')\n",
        "wf.setnchannels(channels)\n",
        "wf.setsampwidth(p.get_sample_size(sample_format))\n",
        "wf.writeframes(b''.join(frames))\n",
        "wf.close()"
      ],
      "metadata": {
        "id": "7wKkpqWH-khy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель whisper-3\n",
        "\n",
        "Выбор данной модели основывался на ее хорошем распозновании текста из голосового файла, также хорошим бонусом является разделение не только на текст, но и на таймкоды.\n",
        "\n",
        "Можно рассмотреть и другие модели, но данная модель является хорошей в своем сегменте. Еще не мало важным фактором является то, что она имеет исходный открытый код и не требует никаких токенов , по сравнению с аналагами.\n",
        "\n",
        "Wisper - данную модель имеет несколько размеров параметров, и в зависимости от выбора размерности и будет зависеть качество. Отличным бонусом в данной модели является то, что мы получаем таймкоды, что дает хорошие возможности при обработки аудио файлов.\n",
        "\n",
        "В пример кода не привожу никакие иные модели, так как они требуют либо токен, либо мощностей для развертывания, которых у меня не хватает. Список моделей, которые были использованы в ходе тестов - pyannote/speaker-diarization, facebook/seamless-m4t-v2-large\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bb_9CDOlEKGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from audio_separator.separator import Separator\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "\n",
        "#@title Загружаем модель whisper-3\n",
        "\n",
        "import stable_whisper\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Устройтво\", device)\n",
        "\n",
        "# Загрузка модели для транскрибации аудиофайлов,\n",
        "# используя архитектуру \"large-3\",\n",
        "# скачивание модели, если она не была предварительно загружена,\n",
        "# и указание корневой директории для загрузки\n",
        "\n",
        "if str(device) == \"cuda\":\n",
        "    whisper_model = stable_whisper.load_model(\n",
        "        'large-v3',\n",
        "        device = \"cuda\",\n",
        "        )\n",
        "else:\n",
        "    whisper_model = stable_whisper.load_model(\n",
        "        'large-v3',\n",
        "        device = device,\n",
        "        in_memory=True,\n",
        "        dq=True\n",
        "        )\n",
        "#@title Функция для транскребации голоса\n",
        "import os\n",
        "\n",
        "\n",
        "def transcribe(input_file):\n",
        "    # Получаем имя файла без расширения из полного пути к input_file\n",
        "    input_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
        "\n",
        "    # Создаем папку для сохранения аудиофайлов, если она не существует\n",
        "    output_folder = f\"{input_filename}\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Выполняем транскрибацию аудиофайла\n",
        "    # с использованием модели stable_whisper\n",
        "    result = whisper_model.transcribe(\n",
        "        os.path.join(output_folder, f\"{input_filename}.mp3\"),\n",
        "        )\n",
        "\n",
        "    # Сохраняем результаты в формате TSV в файл\n",
        "    # с именем, аналогичным названию входного файла\n",
        "    result.save_as_json(os.path.join(output_folder, f\"{input_filename}.json\"))\n",
        "\n",
        "    return \"Done\""
      ],
      "metadata": {
        "id": "nCLLDenvEiYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549671a0-dec9-4215-c323-1ef71798d4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Устройтво cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:46<00:00, 29.0MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -y ruaccent\n",
        "!pip install ruaccent"
      ],
      "metadata": {
        "id": "uZJ2ZjpYABpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VitsModel, AutoTokenizer, set_seed\n",
        "import torch\n",
        "import scipy\n",
        "from ruaccent import RUAccent\n",
        "\n",
        "device = 'cuda' #  'cpu' or 'cuda'\n",
        "\n",
        "speaker = 0 # 0-woman, 1-man\n",
        "\n",
        "set_seed(555)  # make deterministic\n",
        "\n",
        "# load model\n",
        "model_name = \"utrobinmv/tts_ru_free_hf_vits_low_multispeaker\"\n",
        "\n",
        "model = VitsModel.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "# load accentizer\n",
        "accentizer = RUAccent()\n",
        "accentizer.load(omograph_model_size='turbo', use_dictionary=True, device=device)\n",
        "\n",
        "# text\n",
        "text = \"\"\"Я сегодня не приду домой\" и отвечает \"Ну и катись отсюда\"\"\"\n",
        "\n",
        "# the placement of accents\n",
        "text = accentizer.process_all(text)\n",
        "print(text)\n",
        "# н+очью дв+адцать тр+етьего и+юня н+ачал изверг+аться с+амый выс+окий\n",
        "# д+ействующий вулк+ан в евр+азии - ключевск+ой. об +этом сообщ+ила\n",
        "# руковод+итель камч+атской гр+уппы реаг+ирования на вулкан+ические\n",
        "# изверж+ения, вед+ущий на+учный сотр+удник инстит+ута вулканол+огии\n",
        "# и сейсмол+огии дво ран +ольга г+ирина. « зафикс+ированное н+очью не\n",
        "# пр+осто свеч+ение, а верш+инное эксплоз+ивное изверж+ение\n",
        "# стромболи+анского т+ипа. пок+а так+ое изверж+ение ником+у не оп+асно:\n",
        "# ни насел+ению, ни ави+ации » поясн+ила тасс госпож+а г+ирина.\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(**inputs.to(device), speaker_id=speaker).waveform\n",
        "    output = output.detach().cpu().numpy()\n",
        "\n",
        "scipy.io.wavfile.write(\"tts_audio.wav\", rate=model.config.sampling_rate,\n",
        "                       data=output[0])"
      ],
      "metadata": {
        "id": "Hm1lZ4Zf_xTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Запускаем процесс транскрибации"
      ],
      "metadata": {
        "id": "Izgkix--4jIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe(\"audio.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "9MG30uDR_DJN",
        "outputId": "8c5ee197-928b-44e3-f830-fc2481d5280b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribe:   0%|          | 0/132.34 [00:43<?, ?sec/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: russian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribe: 100%|██████████| 132.34/132.34 [06:10<00:00,  2.80s/sec]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/audio/audio.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}