{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Установка зависимостей\n",
        "\n",
        "> Добавить блок с цитатой\n",
        "\n"
      ],
      "metadata": {
        "id": "844HkDAODwSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_8_5XS6oYdB"
      },
      "outputs": [],
      "source": [
        "!pip install audio-separator\n",
        "!pip cache purge\n",
        "!pip install --force-reinstall torch torchvision torchaudio\n",
        "!pip install --force-reinstall onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель whisper-3\n",
        "\n",
        "Выбор данной модели основывался на ее хорошем распозновании текста из голосового файла, также хорошим бонусом является разделение не только на текст, но и на таймкоды.\n",
        "\n",
        "Можно рассмотреть и другие модели, но данная модель является хорошей в своем сегменте. Еще не мало важным фактором является то, что она имеет исходный открытый код и не требует никаких токенов , по сравнению с аналагами.\n",
        "\n",
        "Wisper - данную модель имеет несколько размеров параметров, и в зависимости от выбора размерности и будет зависеть качество.\n",
        "\n",
        "В пример кода не привожу никакие иные модели, так как они требуют либо токен, либо мощностей для развертывания, которых у меня не хватает. Список моделей, которые были использованы в ходе тестов - pyannote/speaker-diarization, facebook/seamless-m4t-v2-large\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bb_9CDOlEKGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from audio_separator.separator import Separator\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "\n",
        "#@title Загружаем модель whisper-3\n",
        "\n",
        "import stable_whisper\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Устройтво\", device)\n",
        "\n",
        "# Загрузка модели для транскрибации аудиофайлов,\n",
        "# используя архитектуру \"large-3\",\n",
        "# скачивание модели, если она не была предварительно загружена,\n",
        "# и указание корневой директории для загрузки\n",
        "\n",
        "if str(device) == \"cuda\":\n",
        "    whisper_model = stable_whisper.load_model(\n",
        "        'large-v3',\n",
        "        device = \"cuda\",\n",
        "        )\n",
        "else:\n",
        "    whisper_model = stable_whisper.load_model(\n",
        "        'large-v3',\n",
        "        device = device,\n",
        "        in_memory=True,\n",
        "        dq=True\n",
        "        )\n",
        "#@title Функция для транскребации голоса\n",
        "import os\n",
        "\n",
        "\n",
        "def transcribe(input_file):\n",
        "    # Получаем имя файла без расширения из полного пути к input_file\n",
        "    input_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
        "\n",
        "    # Создаем папку для сохранения аудиофайлов, если она не существует\n",
        "    output_folder = f\"{input_filename}\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Выполняем транскрибацию аудиофайла\n",
        "    # с использованием модели stable_whisper\n",
        "    result = whisper_model.transcribe(\n",
        "        os.path.join(output_folder, f\"{input_filename}.mp3\"),\n",
        "        )\n",
        "\n",
        "    # Сохраняем результаты в формате TSV в файл\n",
        "    # с именем, аналогичным названию входного файла\n",
        "    result.save_as_json(os.path.join(output_folder, f\"{input_filename}.json\"))\n",
        "\n",
        "    return \"Done\""
      ],
      "metadata": {
        "id": "nCLLDenvEiYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe(\"audio.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "9MG30uDR_DJN",
        "outputId": "8c5ee197-928b-44e3-f830-fc2481d5280b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribe:   0%|          | 0/132.34 [00:43<?, ?sec/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: russian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribe: 100%|██████████| 132.34/132.34 [06:10<00:00,  2.80s/sec]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/audio/audio.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}