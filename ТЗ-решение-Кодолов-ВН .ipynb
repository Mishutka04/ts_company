{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Комментарий:\n",
        "Предоставляю решение первого задания. При решении второго, столкнулся с проблемой реализации, так как я не смог найти open-source решения на python для разделения на различные голоса. Сложность заключается в том, что тут необходимо взаимодействовать с аудио-волнами, частотами, и если оба говорящих имеют +/- одинаковые голосовые показатели, то задача переходит в более сложную стадию и за 4 дня реализовать такое очень сложно. При анализе источников и решений, я нашел решение у СБЕРа, по разделению на голоса, но доступа к данной технологии у меня нету, так как необходима подписка.\n",
        "На данный момент у меня имеется решение для распознования речи и перевод ее в текст (V2T), решения по второй части имеется на половину (Без разделения на персоны), но я готов заняться данной задачей в вашей компании (Если необходимо будет внедрить решение с распознованием персон)"
      ],
      "metadata": {
        "id": "6NDuh_Qg4t7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Установка зависимостей\n",
        "\n",
        "> Добавить блок с цитатой\n",
        "\n"
      ],
      "metadata": {
        "id": "844HkDAODwSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_8_5XS6oYdB"
      },
      "outputs": [],
      "source": [
        "!pip install audio-separator\n",
        "!pip cache purge\n",
        "!pip install --force-reinstall torch torchvision torchaudio\n",
        "!pip install --force-reinstall onnxruntime-gpu\n",
        "!pip install -U git+https://github.com/jianfch/stable-ts.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель whisper-3\n",
        "\n",
        "Выбор данной модели основывался на ее хорошем распозновании текста из голосового файла, также хорошим бонусом является разделение не только на текст, но и на таймкоды.\n",
        "\n",
        "Можно рассмотреть и другие модели, но данная модель является хорошей в своем сегменте. Еще не мало важным фактором является то, что она имеет исходный открытый код и не требует никаких токенов , по сравнению с аналагами.\n",
        "\n",
        "Wisper - данную модель имеет несколько размеров параметров, и в зависимости от выбора размерности и будет зависеть качество. Отличным бонусом в данной модели является то, что мы получаем таймкоды, что дает хорошие возможности при обработки аудио файлов.\n",
        "\n",
        "В пример кода не привожу никакие иные модели, так как они требуют либо токен, либо мощностей для развертывания, которых у меня не хватает. Список моделей, которые были использованы в ходе тестов - pyannote/speaker-diarization, facebook/seamless-m4t-v2-large\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bb_9CDOlEKGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from audio_separator.separator import Separator\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "\n",
        "#@title Загружаем модель whisper-3\n",
        "\n",
        "import stable_whisper\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Устройтво\", device)\n",
        "\n",
        "# Загрузка модели для транскрибации аудиофайлов,\n",
        "# используя архитектуру \"large-3\",\n",
        "# скачивание модели, если она не была предварительно загружена,\n",
        "# и указание корневой директории для загрузки\n",
        "\n",
        "if str(device) == \"cuda\":\n",
        "    whisper_model = stable_whisper.load_model(\n",
        "        'large-v3',\n",
        "        device = \"cuda\",\n",
        "        )\n",
        "else:\n",
        "    whisper_model = stable_whisper.load_model(\n",
        "        'large-v3',\n",
        "        device = device,\n",
        "        in_memory=True,\n",
        "        dq=True\n",
        "        )\n",
        "#@title Функция для транскребации голоса\n",
        "import os\n",
        "\n",
        "\n",
        "def transcribe(input_file):\n",
        "    # Получаем имя файла без расширения из полного пути к input_file\n",
        "    input_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
        "\n",
        "    # Создаем папку для сохранения аудиофайлов, если она не существует\n",
        "    output_folder = f\"{input_filename}\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Выполняем транскрибацию аудиофайла\n",
        "    # с использованием модели stable_whisper\n",
        "    result = whisper_model.transcribe(\n",
        "        os.path.join(output_folder, f\"{input_filename}.mp3\"),\n",
        "        )\n",
        "\n",
        "    # Сохраняем результаты в формате TSV в файл\n",
        "    # с именем, аналогичным названию входного файла\n",
        "    result.save_as_json(os.path.join(output_folder, f\"{input_filename}.json\"))\n",
        "\n",
        "    return \"Done\""
      ],
      "metadata": {
        "id": "nCLLDenvEiYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549671a0-dec9-4215-c323-1ef71798d4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Устройтво cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:46<00:00, 29.0MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Запускаем процесс транскрибации"
      ],
      "metadata": {
        "id": "Izgkix--4jIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe(\"audio.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "9MG30uDR_DJN",
        "outputId": "8c5ee197-928b-44e3-f830-fc2481d5280b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribe:   0%|          | 0/132.34 [00:43<?, ?sec/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: russian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribe: 100%|██████████| 132.34/132.34 [06:10<00:00,  2.80s/sec]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/audio/audio.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}